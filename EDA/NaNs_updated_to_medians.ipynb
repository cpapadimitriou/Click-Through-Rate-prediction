{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W261 Final Project\n",
    "\n",
    "#### *Anusha Munjuluri, Arvindh Ganesan, Kim Vignola, Christina Papadimitriou*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store path to notebook\n",
    "PWD = !pwd\n",
    "PWD = PWD[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"final_project\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Question Formulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Algorithm Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\t1\t1\t5\t0\t1382\t4\t15\t2\t181\t1\t2\t\t2\t68fd1e64\t80e26c9b\tfb936136\t7b4723c4\t25c83c98\t7e0ccccf\tde7995b8\t1f89b562\ta73ee510\ta8cd5504\tb2cb9c98\t37c9c164\t2824a5f6\t1adce6ef\t8ba8b39a\t891b62e7\te5ba7672\tf54016b9\t21ddcdc9\tb1252a9d\t07b5194c\t\t3a171ecb\tc5c50484\te8b83407\t9727dd16\n"
     ]
    }
   ],
   "source": [
    "# take a look at the data\n",
    "!head -n 1 data/train.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "fullTrainRDD = sc.textFile('data/train.txt')\n",
    "testRDD = sc.textFile('data/test.txt')\n",
    "\n",
    "FIELDS = ['I1','I2','I3','I4','I5','I6','I7','I8','I9','I10','I11','I12','I13',\n",
    "          'C1','C2','C3','C4','C5','C6','C7','C8','C9','C10','C11','C12','C13','C14',\n",
    "          'C15','C16','C17','C18','C19','C20','C21','C22','C23','C24','C25','C26','Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows in train/test data\n",
    "print(f\"Number of records in train data: {fullTrainRDD.count()} ...\")\n",
    "print(f\"Number of records in test data: {testRDD.count()} ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 80/20 (pseudo)random train/test split \n",
    "trainRDD, heldOutRDD = fullTrainRDD.randomSplit([0.8,0.2], seed = 1)\n",
    "print(f\"... held out {heldOutRDD.count()} records for evaluation and assigned {trainRDD.count()} for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyRDD, trainRDD2 = trainRDD.randomSplit([0.001,0.999], seed = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1\\t5\\t2\\t\\t\\t1382\\t17\\t78\\t25\\t76\\t0\\t9\\t\\t\\t05db9164\\t942f9a8d\\t56472604\\t53a5d493\\t25c83c98\\t\\t49b74ebc\\t6c41e35e\\ta73ee510\\te113fc4b\\tc4adf918\\t08531bcb\\t85dbe138\\t1adce6ef\\tae97ecc3\\t76b06ec3\\te5ba7672\\t1f868fdd\\t9437f62f\\ta458ea53\\tff4c70b8\\t\\t32c7478e\\tda89b7d5\\t7a402766\\tc7beb94e',\n",
       " '1\\t2\\t12\\t8\\t3\\t937\\t7\\t36\\t6\\t73\\t1\\t10\\t\\t4\\t05db9164\\tbce95927\\t02391f51\\tb9c629a9\\t25c83c98\\t7e0ccccf\\t9971a939\\t6a698541\\ta73ee510\\t2124a520\\t3ac87d37\\t2397259a\\tcde3ec68\\t07d13a8f\\tfec218c0\\td37efe8c\\te5ba7672\\t04d863d5\\t21ddcdc9\\t5840adea\\tb6119319\\t\\t423fab69\\t45ab94c8\\te8b83407\\tb13f4ade',\n",
       " '0\\t\\t51\\t74\\t\\t39039\\t65\\t1\\t0\\t5\\t\\t0\\t\\t\\t05db9164\\t0468d672\\t1c74e7a5\\ta98187d1\\t25c83c98\\tfe6b92e5\\t306a1d05\\tf504a6f4\\ta73ee510\\t3b08e48b\\t788bd9f4\\t6f0b856c\\t71b17693\\t07d13a8f\\tb4512bcd\\t6b56c939\\t07c540c4\\t0c4e94df\\t21ddcdc9\\t5840adea\\tf7d23965\\t\\t93bad2c0\\t61e3864e\\tea9a246c\\tfcd456fa',\n",
       " '0\\t\\t0\\t2\\t4\\t3288\\t101\\t3\\t23\\t37\\t\\t1\\t\\t21\\t05db9164\\td833535f\\tb00d1501\\td16679b9\\t4cf72387\\t7e0ccccf\\t9eec359f\\t0b153874\\ta73ee510\\tb8fa4771\\t636405ac\\te0d76380\\t31b42deb\\tb28479f6\\ta733d362\\t1203a270\\td4bb7bd8\\t281769c2\\t\\t\\t73d06dde\\t\\t3a171ecb\\taee52b6f\\t\\t',\n",
       " '0\\t3\\t28\\t3\\t19\\t799\\t33\\t3\\t30\\t33\\t1\\t1\\t\\t29\\t05db9164\\td833535f\\td032c263\\tc18be181\\t25c83c98\\t7e0ccccf\\t705feb79\\t1f89b562\\ta73ee510\\tefea433b\\tcff871dc\\tdfbb09fb\\t64533206\\tb28479f6\\te2502ec9\\t84898b2a\\te5ba7672\\t42a2edb9\\t\\t\\t0014c32a\\t\\t32c7478e\\t3b183c5c\\t\\t']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toyRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def parse(line):\n",
    "    \"\"\"\n",
    "    Map line --> tuple of (features, label)\n",
    "    \"\"\"\n",
    "    fields = np.array(line.split('\\t'))\n",
    "    features,label = fields[1:14], fields[0]\n",
    "    return(features, label)\n",
    "\n",
    "def edit_data_types(line):\n",
    "    \"\"\"\n",
    "    Map tuple of (features, label) --> tuple of (formated features, label)\n",
    "    \n",
    "    * '' is replaced with 'null'\n",
    "    * numerical fields are converted to integers\n",
    "    \"\"\"\n",
    "    features, label = line[0], line[1]\n",
    "    formated_features = []\n",
    "    for i, value in enumerate(features):\n",
    "        if value == '':\n",
    "            formated_features.append(np.nan)\n",
    "        else:\n",
    "            if i < 13:\n",
    "                formated_features.append(float(value)) \n",
    "            else:\n",
    "                formated_features.append(value)\n",
    "    return (formated_features, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainRDDCached = trainRDD.map(parse).map(edit_data_types).cache()\n",
    "toyRDDCached1 = toyRDD.map(parse).map(edit_data_types).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([5.0, 2.0, nan, nan, 1382.0, 17.0, 78.0, 25.0, 76.0, 0.0, 9.0, nan, nan], '1')]\n"
     ]
    }
   ],
   "source": [
    "print(toyRDDCached1.take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.array(toyRDDCached1.map(lambda x: np.append(x[0], [x[1]])).takeSample(False, 1000))\n",
    "sample_df = pd.DataFrame(np.array(sample), columns = ['I1','I2','I3','I4','I5','I6','I7','I8','I9','I10','I11','I12','I13', 'Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = (['I1','I2','I3','I4','I5','I6','I7','I8','I9','I10','I11','I12','I13', 'Label'])\n",
    "#columns = ['I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'I10', 'I11', 'I12', 'I13']\n",
    "sample_numeric = sample_df.reindex(columns=columns)\n",
    "sample_numeric[columns] = sample_numeric[columns].astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.6761061946902656, 129.768, 19.083969465648856, 7.478535353535354, 24031.09182643794, 113.30208333333333, 16.173821989528797, 12.457, 102.717277486911, 0.6495575221238938, 2.8293193717277485, 1.1415929203539823, 8.308080808080808]\n",
      "[9.04753693892924, 460.60738615007034, 35.28575565553717, 8.70109965628185, 92782.65943349876, 343.9023789473689, 49.37351119685013, 12.67218019916068, 232.37267788885407, 0.7196513282846247, 5.737100628411079, 5.262771665595769, 11.208584163174447]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Get means and standard deviations. Ideally we should do this in the RDD vs. pandas\"\"\"\n",
    "\n",
    "means = []\n",
    "stdevs = []\n",
    "\n",
    "for i in sample_numeric.columns[0:13]:\n",
    "    mean = np.nanmean(sample_numeric[i])\n",
    "    means.append(mean)\n",
    "    std = np.nanstd(sample_numeric[i])\n",
    "    stdevs.append(std)\n",
    "        \n",
    "print(means)\n",
    "print(stdevs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0000e+00 4.0000e+00 6.0000e+00 4.0000e+00 1.1855e+03 1.4000e+01\n",
      " 7.0000e+00 8.0000e+00 3.2000e+01 1.0000e+00 2.0000e+00 0.0000e+00\n",
      " 3.0000e+00 1.0000e+00]\n",
      "[2.0000e+00 4.0000e+00 6.0000e+00 4.0000e+00 1.1855e+03 1.4000e+01\n",
      " 7.0000e+00 8.0000e+00 3.2000e+01 1.0000e+00 2.0000e+00 0.0000e+00\n",
      " 3.0000e+00 1.0000e+00]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Get medians for each class. Ideally we should do this in the RDD vs. pandas\"\"\"\n",
    "\n",
    "median1 = np.array(sample_numeric[sample_numeric['Label'] == 1.0].median().tolist())\n",
    "print(median1)\n",
    "\n",
    "median0 = np.array(sample_numeric[sample_numeric['Label'] == 0.0].median().tolist())\n",
    "print(median1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def parse(line):\n",
    "    \"\"\"\n",
    "    Map line --> tuple of (features, label)\n",
    "    \"\"\"\n",
    "    fields = np.array(line.split('\\t'))\n",
    "    features,label = fields[1:14], fields[0]\n",
    "    return(features, label)\n",
    "\n",
    "\n",
    "def update_nans(line):\n",
    "    \"\"\"\n",
    "    Map tuple of (features, label) --> tuple of (formated features, label)\n",
    "    \n",
    "    * '' is replaced with 'null'\n",
    "    * numerical fields are converted to integers\n",
    "    \"\"\"\n",
    "    \n",
    "    #median1 = np.array([2.0, 3.5, 4.0, 4.0, 1362.0, 13.5, 8.0, 7.0, 42.5, 1.0, 2.0, 0.0, 3.0, 1.0])\n",
    "    #median0 = np.array([0.0, 2.0, 7.0, 5.0, 3539.0, 46.5, 2.0, 8.0, 38.5, 0.0, 1.0, 0.0, 5.0, 0.0])\n",
    "        \n",
    "    features, label = line[0], float(line[1])\n",
    "    formated_features = []\n",
    "    for i, value in enumerate(features):\n",
    "        if value == '' and label == 1.0:\n",
    "            formated_features.append(float(median1[i]))\n",
    "        elif value == '' and label == 0.0:\n",
    "            formated_features.append(float(median0[i]))\n",
    "        else:\n",
    "            if i < 13:\n",
    "                formated_features.append(float(value)) \n",
    "            else:\n",
    "                formated_features.append(value)\n",
    "    return (formated_features, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "toyRDDCached = toyRDD.map(parse).map(update_nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part d - helper function to normalize the data (FILL IN THE MISSING CODE BELOW)\n",
    "def normalize(dataRDD):\n",
    "    \n",
    "    featureMeans = np.array(means)\n",
    "    featureStdev = np.array(stdevs)\n",
    "    \n",
    "    #sc.broadcast(featureMeans)\n",
    "    #sc.broadcast(featureStdevs)\n",
    "    \n",
    "    ################ YOUR CODE HERE #############\n",
    "        \n",
    "    normedRDD = dataRDD.map(lambda x: ((x[0]-featureMeans)/featureStdev, x[1]))\n",
    "    \n",
    "    ################ FILL IN YOUR CODE HERE #############\n",
    "    \n",
    "    return normedRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 0.27080439, -0.26654119, -0.32657669, -0.41851167, -0.24265445,\n",
       "         -0.38302342,  0.86688289,  0.89503667, -0.15117633, -0.84217242,\n",
       "          1.05136664, -0.40703114, -0.54504306]), 1.0),\n",
       " (array([-0.12509599, -0.24048226, -0.24962123, -0.54366042, -0.24878794,\n",
       "         -0.42130147,  0.26723367, -0.5235247 , -0.16401474,  0.60118154,\n",
       "          1.22386501, -0.40703114, -0.43805518]), 1.0),\n",
       " (array([-0.38902958, -0.13885242,  1.02014377, -0.29336292,  0.27637699,\n",
       "         -0.19928876, -0.23247401, -0.97149145, -0.45501867, -0.84217242,\n",
       "         -0.50111868, -0.40703114, -0.3310673 ]), 0.0)]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normedRDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EDA & Discussion of Challenges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample = np.array(trainRDDCached.map(lambda x: np.append(x[0], [x[1]])).takeSample(False, 1000))\n",
    "# sample_df = pd.DataFrame(np.array(sample), columns = FIELDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.iloc[:,0:21].describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.iloc[:,21:39].describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Take a subset of the dataframe with only numeric features\n",
    "# sample_numeric = sample_df[FIELDS[0:13]]\n",
    "# columns = ['I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'I10', 'I11', 'I12', 'I13']\n",
    "# sample_numeric = sample_num.reindex(columns=columns)\n",
    "# sample_numeric[columns] = sample_numeric[columns].astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a look at histograms for each feature (RUN THIS CELL AS IS)\n",
    "sample_numeric.hist(figsize=(23,15), bins=15)\n",
    "#sample_numeric[FIELDS[:-1]].hist(figsize=(15,15), bins=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part b -  plot boxplots of each feature vs. the outcome (RUN THIS CELL AS IS)\n",
    "\n",
    "fig, ax_grid = plt.subplots(5, 3, figsize=(23,15))\n",
    "y = sample_df['Label']\n",
    "for idx, feature in enumerate(FIELDS[0:13]):\n",
    "    x = sample_num[feature]\n",
    "    sns.boxplot(x, y, ax=ax_grid[idx//3][idx%3], orient='h', linewidth=.5)\n",
    "    ax_grid[idx//3][idx%3].invert_yaxis()\n",
    "fig.suptitle(\"BoxPlots by Label\", fontsize=15, y=0.9)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = sample_numeric[FIELDS[:13]].corr()\n",
    "fig, ax = plt.subplots(figsize=(15, 13))\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "cmap = sns.diverging_palette(10, 240, as_cmap=True)\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, center=0, linewidths=.5)\n",
    "plt.title(\"Correlations between features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part e - define your baseline model here\n",
    "BASELINE = np.array([1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part d - write function to compute loss (FILL IN MISSING CODE BELOW)\n",
    "def LRLoss(cachedRDD, W):\n",
    "    \"\"\"\n",
    "    Compute mean squared error.\n",
    "    Args:\n",
    "        dataRDD - each record is a tuple of (features_array, y)\n",
    "        W       - (array) model coefficients with bias at index 0\n",
    "    \"\"\"\n",
    "    augmentedData = cachedRDD.map(lambda x: (np.append([1.0], x[0]), x[1]))\n",
    "    ################## YOUR CODE HERE ##################\n",
    "    \n",
    "    \n",
    "    loss = augmentedData.map(lambda x: np.log(1.0 + np.exp(np.multiply(-x[1], (np.dot(W, x[0])))))).mean()\n",
    "\n",
    "    #loss = augmentedData.map(lambda x: np.log(1.0 + np.exp(np.multiply(-x[1], (np.dot(W, x[0][1:]) + x[0][0]))))).sum()\n",
    "\n",
    "    ################## (END) YOUR CODE ##################\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LRLoss(normedRDD, BASELINE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.array([meanQuality, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
    "learningRate = 0.1\n",
    "#augmentedData = toyRDDnumeric.map(lambda x: (np.append([1.0], x[0]), x[1])).cache()\n",
    "#grad = augmentedData.map(lambda x: np.dot(np.multiply(-x[1], (1.0 - 1.0/(1.0 + np.exp(np.multiply(-x[1], (np.dot(W, x[0][1:]) + x[0][0]))))), x[0]))).sum()\n",
    "#new_model = W - (learningRate * grad)\n",
    "\n",
    "\n",
    "grad = augmentedData.map(lambda x: (-x[1] * (1.0-(1.0/(1.0 + (np.exp(np.multiply(-x[1], (np.dot(W, x[0][1:]) + x[0][0])))))))) * x[0][1:]).sum()\n",
    "print(grad)\n",
    "\n",
    "new_model = W - (learningRate * grad)\n",
    "print(new_model)\n",
    "#grad = np.dot(loss_2, x[0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part b - function to perform a single GD step\n",
    "def GDUpdate(dataRDD, W, learningRate):\n",
    "    \"\"\"\n",
    "    Perform one OLS gradient descent step/update.\n",
    "    Args:\n",
    "        dataRDD - records are tuples of (features_array, y)\n",
    "        W       - (array) model coefficients with bias at index 0\n",
    "    Returns:\n",
    "        new_model - (array) updated coefficients, bias at index 0\n",
    "    \"\"\"\n",
    "    # add a bias 'feature' of 1 at index 0\n",
    "    augmentedData = dataRDD.map(lambda x: (np.append([1.0], x[0]), x[1])).cache()\n",
    "    \n",
    "    ################## YOUR CODE HERE ################# \n",
    "    \n",
    "    grad = augmentedData.map(lambda x: (-x[1] * (1.0-(1.0/(1.0 + (np.exp(np.multiply(-x[1], (np.dot(W, x[0]))))))))) * x[0]).mean()\n",
    "\n",
    "    new_model = W - (learningRate * grad)\n",
    "\n",
    "    ################## (END) YOUR CODE ################# \n",
    "\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GDUpdate(normedRDD, BASELINE, learningRate=learningRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part c - take a look at a few Gradient Descent steps (RUN THIS CELL AS IS)\n",
    "nSteps = 5\n",
    "model = BASELINE\n",
    "print(f\"BASELINE:  Loss = {LRLoss(normedRDD,model)}\")\n",
    "for idx in range(nSteps):\n",
    "    print(\"----------\")\n",
    "    print(f\"STEP: {idx+1}\")\n",
    "    model = GDUpdate(normedRDD, model)\n",
    "    loss = LRLoss(normedRDD, model)\n",
    "    print(f\"Loss: {loss}\")\n",
    "    print(f\"Model: {[round(w,3) for w in model]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear_weights = nb.feature_log_prob_[1] - nb.feature_log_prob_[0]\n",
    "\n",
    "# top_negative_features = np.argsort(linear_weights)[0:10]\n",
    "\n",
    "# top_positive_features = np.flip(np.argsort(linear_weights)[-10:],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part b - OLS gradient descent function\n",
    "def GradientDescent(trainRDD, testRDD, wInit, nSteps = 20, \n",
    "                    learningRate = 0.1, verbose = False):\n",
    "    \"\"\"\n",
    "    Perform nSteps iterations of OLS gradient descent and \n",
    "    track loss on a test and train set. Return lists of\n",
    "    test/train loss and the models themselves.\n",
    "    \"\"\"\n",
    "    # initialize lists to track model performance\n",
    "    train_history, test_history, model_history = [], [], []\n",
    "    \n",
    "    # perform n updates & compute test and train loss after each\n",
    "    model = wInit\n",
    "    for idx in range(nSteps): \n",
    "        \n",
    "        ############## YOUR CODE HERE #############\n",
    "        \n",
    "        model = GDUpdate(trainRDD, model)\n",
    "        training_loss = OLSLoss(trainRDD, model)\n",
    "        test_loss = OLSLoss(testRDD, model)\n",
    "                \n",
    "        ############## (END) YOUR CODE #############\n",
    "        \n",
    "        # keep track of test/train loss for plotting\n",
    "        train_history.append(training_loss)\n",
    "        test_history.append(test_loss)\n",
    "        model_history.append(model)\n",
    "        \n",
    "        # console output if desired\n",
    "        if verbose:\n",
    "            print(\"----------\")\n",
    "            print(f\"STEP: {idx+1}\")\n",
    "            print(f\"training loss: {training_loss}\")\n",
    "            print(f\"test loss: {test_loss}\")\n",
    "            print(f\"Model: {[round(w,3) for w in model]}\")\n",
    "    return train_history, test_history, model_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot error curves - RUN THIS CELL AS IS\n",
    "def plotErrorCurves(trainLoss, testLoss, title = None):\n",
    "    \"\"\"\n",
    "    Helper function for plotting.\n",
    "    Args: trainLoss (list of MSE) , testLoss (list of MSE)\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1,1,figsize = (16,8))\n",
    "    x = list(range(len(trainLoss)))[1:]\n",
    "    ax.plot(x, trainLoss[1:], 'k--', label='Training Loss')\n",
    "    ax.plot(x, testLoss[1:], 'r--', label='Test Loss')\n",
    "    ax.legend(loc='upper right', fontsize='x-large')\n",
    "    plt.xlabel('Number of Iterations')\n",
    "    plt.ylabel('Mean Squared Error')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run 50 iterations (RUN THIS CELL AS IS)\n",
    "wInit = BASELINE\n",
    "trainRDD, testRDD = normedRDD.randomSplit([0.8,0.2], seed = 2018)\n",
    "start = time.time()\n",
    "MSEtrain, MSEtest, models = GradientDescent(trainRDD, testRDD, wInit, nSteps = 50)\n",
    "print(f\"\\n... trained {len(models)} iterations in {time.time() - start} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from async\n",
    "\n",
    "def logisticReg_GD_Spark(data,y,w=None,eta=0.05,iter_num=500,regPara=0.01, stopCriteria=0.0001,reg=\"Lasso\"): \n",
    "    #eta learning rate \n",
    "    #regPara \n",
    "    dataRDD = sc.parallelize(np.append(y[:,None],data,axis=1)).cache() \n",
    "    if w is None: \n",
    "       w = np.random.normal(size=data.shape[1]+1) \n",
    "    for i in range(iter_num): \n",
    "       w_broadcast = sc.broadcast(w) \n",
    "       g = dataRDD.map(lambda x: −x[0]*{1−1/(1+np.exp(−x[0]) \n",
    "       *np.dot(w_broadcast.value,np.append(x[1:],1))))) \\ \n",
    "             *np.append(x[1:],1)).reduce[lambda x,y:x+y)/data.shape[0] \n",
    "             # Gradient of logloss \n",
    "       if reg == \"Ridge\": \n",
    "          wreg = w*1 \n",
    "          wreg[−1] = 0 #last value of weight vector is bias term; \n",
    "          ignore in regularization \n",
    "       elif reg == \"Lasso\": \n",
    "          wreg = w*1 \n",
    "          wreg[−1] = 0 #last value of weight vector is bias term; \n",
    "          ignore in regularization \n",
    "          wreg = (wreg>0).astype(int)*2−1 \n",
    "       else: \n",
    "          wreg = np.zeros(w.shape[0]) \n",
    "       wdelta = eta*(g+regPara*wreg) #gradient: hinge loss + regularized term \n",
    "       if sum(abs(wdelta))<=stopCriteria*sum(abs(w)): # converged as updates \n",
    "       to weight vector are small \n",
    "          break \n",
    "       w = w − wdelta \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 80/20 (pseudo)random train/test split \n",
    "trainRDD, heldOutRDD = fullTrainRDD.randomSplit([0.8,0.2], seed = 1)\n",
    "print(f\"... held out {heldOutRDD.count()} records for evaluation and assigned {trainRDD.count()} for training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "# Load and parse the data file into an RDD of LabeledPoint.\n",
    "data = MLUtils.loadLibSVMFile(sc, 'data/mllib/sample_libsvm_data.txt')\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "#  Empty categoricalFeaturesInfo indicates all features are continuous.\n",
    "model = DecisionTree.trainClassifier(trainingData, numClasses=2, categoricalFeaturesInfo={},\n",
    "                                     impurity='gini', maxDepth=5, maxBins=32)\n",
    "\n",
    "# Evaluate model on test instances and compute test error\n",
    "predictions = model.predict(testData.map(lambda x: x.features))\n",
    "labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
    "testErr = labelsAndPredictions.filter(\n",
    "    lambda lp: lp[0] != lp[1]).count() / float(testData.count())\n",
    "print('Test Error = ' + str(testErr))\n",
    "print('Learned classification tree model:')\n",
    "print(model.toDebugString())\n",
    "\n",
    "# Save and load model\n",
    "model.save(sc, \"target/tmp/myDecisionTreeClassificationModel\")\n",
    "sameModel = DecisionTreeModel.load(sc, \"target/tmp/myDecisionTreeClassificationModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "# Load and parse the data file into an RDD of LabeledPoint.\n",
    "data = MLUtils.loadLibSVMFile(sc, 'data/mllib/sample_libsvm_data.txt')\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a DecisionTree model.\n",
    "#  Empty categoricalFeaturesInfo indicates all features are continuous.\n",
    "model = DecisionTree.trainRegressor(trainingData, categoricalFeaturesInfo={},\n",
    "                                    impurity='variance', maxDepth=5, maxBins=32)\n",
    "\n",
    "# Evaluate model on test instances and compute test error\n",
    "predictions = model.predict(testData.map(lambda x: x.features))\n",
    "labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
    "testMSE = labelsAndPredictions.map(lambda lp: (lp[0] - lp[1]) * (lp[0] - lp[1])).sum() /\\\n",
    "    float(testData.count())\n",
    "print('Test Mean Squared Error = ' + str(testMSE))\n",
    "print('Learned regression tree model:')\n",
    "print(model.toDebugString())\n",
    "\n",
    "# Save and load model\n",
    "model.save(sc, \"target/tmp/myDecisionTreeRegressionModel\")\n",
    "sameModel = DecisionTreeModel.load(sc, \"target/tmp/myDecisionTreeRegressionModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Application of Course Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
